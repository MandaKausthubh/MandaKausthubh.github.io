<!DOCTYPE html>
<html lang="en"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">Overview of Introductory Reinforcement Learning | Manda Kausthubh&#39;s blog</title>
<meta property="og:title" content="Overview of Introductory Reinforcement Learning | Manda Kausthubh&#39;s blog" />
<meta name="twitter:title" content="Overview of Introductory Reinforcement Learning | Manda Kausthubh&#39;s blog" />
<meta itemprop="name" content="Overview of Introductory Reinforcement Learning | Manda Kausthubh&#39;s blog" />
<meta name="application-name" content="Overview of Introductory Reinforcement Learning | Manda Kausthubh&#39;s blog" />
<meta property="og:site_name" content="Awesome hugo blog" />

<meta name="description" content="Minimal Hugo blog theme with light and dark mode support">
<meta itemprop="description" content="Minimal Hugo blog theme with light and dark mode support" />
<meta property="og:description" content="Minimal Hugo blog theme with light and dark mode support" />
<meta name="twitter:description" content="Minimal Hugo blog theme with light and dark mode support" />

<meta property="og:locale" content="en" />
<meta name="language" content="en" />

  <link rel="alternate" hreflang="en" href="http://localhost:1313/posts/generalisation-theory/proof-of-hoeffdings-inequality/" title="English" />





    
    
    

    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content=2025-04-13T03:53:13&#43;0530 />
    <meta property="article:published_time" content=2025-04-13T03:53:13&#43;0530 />
    <meta property="og:url" content="http://localhost:1313/posts/generalisation-theory/proof-of-hoeffdings-inequality/" />

    
    <meta property="og:article:author" content="Kausthubh Manda" />
    <meta property="article:author" content="Kausthubh Manda" />
    <meta name="author" content="Kausthubh Manda" />
    
    

    

    <script defer type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "Overview of Introductory Reinforcement Learning",
        "author": {
        "@type": "Person",
        "name": ""
        },
        "datePublished": "2025-04-13",
        "description": "",
        "wordCount":  661 ,
        "mainEntityOfPage": "True",
        "dateModified": "2025-04-13",
        "image": {
        "@type": "imageObject",
        "url": ""
        },
        "publisher": {
        "@type": "Organization",
        "name": "Manda Kausthubh\u0027s blog"
        }
    }
    </script>


<meta name="generator" content="Hugo 0.146.2">

    
    <meta property="og:url" content="http://localhost:1313/posts/generalisation-theory/proof-of-hoeffdings-inequality/">
  <meta property="og:site_name" content="Manda Kausthubh&#39;s blog">
  <meta property="og:title" content="Overview of Introductory Reinforcement Learning">
  <meta property="og:description" content="What is Hoeffding’s Inequality ? Given a sequence of Random Variables that act as I.I.Ds (Identical Independently Distributions) $Z_{1}, Z_{2}, Z_{3} \dots Z_{n}$ with mean $\mu$ and $\mathbf{P}(a \leq Z_{i} \leq b) = 1$ then for any $\epsilon &gt; 0$ we have the following:
$$ \mathbf{P}(|\bar{Z}_{n} &gt; \epsilon |) \leq 2 \exp\left( \frac{-2n\epsilon^{2}}{(b-a)^{2}} \right) $$ where $\bar{Z_{n}}=\frac{1}{N} \sum_{i=1}^{N}Z_{i}$.
Why should anyone care about this at all?? This is well explained in Abu Mostafa’s book: Learning from data: A Short Course. This is an excellent book for anyone to get started on theoretical machine learning and is a must read. This book was based on the course that he had taught at CalTech.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-13T03:53:13+05:30">
    <meta property="article:modified_time" content="2025-04-13T03:53:13+05:30">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Overview of Introductory Reinforcement Learning">
  <meta name="twitter:description" content="What is Hoeffding’s Inequality ? Given a sequence of Random Variables that act as I.I.Ds (Identical Independently Distributions) $Z_{1}, Z_{2}, Z_{3} \dots Z_{n}$ with mean $\mu$ and $\mathbf{P}(a \leq Z_{i} \leq b) = 1$ then for any $\epsilon &gt; 0$ we have the following:
$$ \mathbf{P}(|\bar{Z}_{n} &gt; \epsilon |) \leq 2 \exp\left( \frac{-2n\epsilon^{2}}{(b-a)^{2}} \right) $$ where $\bar{Z_{n}}=\frac{1}{N} \sum_{i=1}^{N}Z_{i}$.
Why should anyone care about this at all?? This is well explained in Abu Mostafa’s book: Learning from data: A Short Course. This is an excellent book for anyone to get started on theoretical machine learning and is a must read. This book was based on the course that he had taught at CalTech.">


    

    <link rel="canonical" href="http://localhost:1313/posts/generalisation-theory/proof-of-hoeffdings-inequality/">
    <link href="/style.min.2d921c18cf1ec555ffc03d59a8adc211c402c68c930c27d6a0c306ab175a8d09.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="http://localhost:1313/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
    integrity="sha512-fHwaWebuwA7NSF5Qg/af4UeDx9XqUpYpOGgubo3yWu+b2IQR4UeQwbb42Ti7gVAjNtVoI/I9TEoYeu9omwcC6g==" crossorigin="anonymous" crossorigin="anonymous" />


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
    integrity="sha512-LQNxIMR5rXv7o+b1l8+N1EZMfhG7iFZ9HhnbJkTp4zjNr5Wvst75AqUeFDxeRUa7l5vEDyUiAip//r+EFLLCyA=="
    crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX+yKMUFHzjaH2+AnM6vp2Xs+gNmaBAVWJjSmuPw76Efg==" crossorigin="anonymous" onload="renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true},
        {left: '$', right: '$', display: false}
      ]
    });"></script>

    
</head>

<body data-theme = "dark" class="notransition">

<script src="/js/theme.js"></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="http://localhost:1313/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title></title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/posts/">
                        Posts
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/pages/aboutme/">
                        CV
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">Overview of Introductory Reinforcement Learning</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-04-13T03:53:13&#43;05:30" itemprop="datePublished"> Apr 13, 2025 </time>
                </div>
                
            </header>
            
    
        
            
        
    
    <details class="toc" open>
        <summary><b></b></summary>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#proof-of-hoeffdings-inequality">Proof of Hoeffding&rsquo;s inequality:</a>
      <ul>
        <li><a href="#check-point-1-markovs-inequality">Check Point 1: Markov&rsquo;s inequality</a></li>
        <li><a href="#check-point-2-chebyshevs-inequality">Check Point 2: Chebyshev&rsquo;s Inequality</a></li>
        <li><a href="#check-point-3-moment-generating-functions-and-chernoff-bounds">Check Point 3: Moment Generating Functions and Chernoff Bounds</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </details>
            <div class="page-content">
                <h1 id="what-is-hoeffdings-inequality-">What is Hoeffding&rsquo;s Inequality ?</h1>
<p>Given a sequence of Random Variables that act as I.I.Ds (Identical Independently Distributions) $Z_{1}, Z_{2}, Z_{3} \dots Z_{n}$ with mean $\mu$ and $\mathbf{P}(a \leq Z_{i} \leq b) = 1$ then for any $\epsilon &gt; 0$ we have the following:</p>
<p>
$$
\mathbf{P}(|\bar{Z}_{n} > \epsilon |) \leq 2 \exp\left( \frac{-2n\epsilon^{2}}{(b-a)^{2}} \right)
$$
</p>
<p>where $\bar{Z_{n}}=\frac{1}{N} \sum_{i=1}^{N}Z_{i}$.</p>
<p>Why should anyone care about this at all?? This is well explained in Abu Mostafa&rsquo;s book: <strong>Learning from data: A Short Course</strong>. This is an excellent book for anyone to get started on theoretical machine learning and is a must read. This book was based on the course that he had taught at <strong>CalTech</strong>.</p>
<p>One can interpret this as follows: the probability that the mean of the independent samples one collects from a distribution deviates from the mean of the original distribution with at tolerance $\epsilon$ is exponentially decreasing with the number of samples one collects $n$. This is very important thing for folk in machine learning and data science. This is one of the founding basis for the belief that: <em>More data gives better results</em>. We will see in the next few blogs how this plays into the idea of generalisation in Machine Learning Theory.</p>
<h2 id="proof-of-hoeffdings-inequality">Proof of Hoeffding&rsquo;s inequality:</h2>
<p>In order to prove Hoeffding&rsquo;s inequality we prove some other smaller theorems who consequence in what we require:</p>
<h3 id="check-point-1-markovs-inequality">Check Point 1: Markov&rsquo;s inequality</h3>
<p>Let $Z \geq 0$ be a non-negative random variable. Then $\forall\ t&gt;0$:</p>
<p>
$$
\mathbf{P}(Z \geq t) \leq \frac{\mathbf{E}[Z]}{t}
$$
</p>
<p><strong>Proof:</strong> This is simple and probably familiar to most of you, but let&rsquo;s go over this anyway:</p>
<p>
$$
\begin{aligned}
 \mathbf{P} (Z \geq t) & = \int_{t}^{\infty} p(x)dx \\
 & \leq \int_{t}^{\infty} p(x)dx \leq \int_{t}^{\infty} \frac{x}{t} p(x)dx \\ \\
 & \leq \frac{1}{t} \int_{t}^{\infty} x p(x)dx \\ \\
 & \leq \frac{1}{t}\int_{0}^{\infty} xp(x)dx = \frac{\mathbf{E}[Z]}{t}\\
\end{aligned}
$$
</p>
<p>Hence we have Markov&rsquo;s: $\mathbf{P}(Z \geq t) \leq \frac{\mathbf{E}[Z]}{t}$</p>
<h3 id="check-point-2-chebyshevs-inequality">Check Point 2: Chebyshev&rsquo;s Inequality</h3>
<p>Let $Z$ be a random variable with $\mathbf{Var}(Z)$ being finite. The for $t &gt; 0$ we have:</p>
<p>
$$
\mathbf{P}(|Z - \mathbf{E}[Z]| \geq \epsilon) < \frac{\mathbf{Var}(Z)}{t^{2}}
$$
</p>
<p>The proof for this is a consequence of the previous Markov Inequality:</p>
<p>
$$
\begin{aligned}
\mathbf{P}(|Z - \mathbf{E}(Z)| \geq \epsilon)  & = \mathbf{P} ((Z - \mathbf{E}[Z])^{2} \geq \epsilon^{2}) \\
 & \leq \frac{\mathbf{E} [(Z-E[Z])^{2}]}{\epsilon^{2}} = \frac{\mathbf{Var(Z)}}{\epsilon^{2}}
\end{aligned}
$$
</p>
<p>Hence we have the following: $\mathbf{P}(|Z - \mathbf{E}[Z]| \geq \epsilon) &lt; \frac{\mathbf{Var}(Z)}{t^{2}}$.
Some further observations from this is: When ever we have $Z_{1}, Z_{2}, Z_{3}\dots Z_{n}$ are I.I.Ds with $\mathbf{E}[Z_{i}]=0$ we have the following:</p>
<p>
$$
\mathbf{Var} (\bar{Z}) = \frac{1}{n}\sum_{i,j\leq n}\mathbf{E}[Z_{i}Z_{j}] 
$$
</p>
<p>Proof of this is:</p>
<p>
$$
\begin{aligned}
 \sum_{i,j \leq n} \mathbf{E}[Z_{i} Z_{j}] &= \sum_{i=1}^{n} \mathbf{E}[Z_{i}^{2}] + \sum_{i \neq j} \mathbf{E}[Z_{i} Z_{j}]  \\
 & =  \sum_{i=1}^{n} \mathbf{E}[Z_{i}^{2}] + \sum_{i \neq j} \mathbf{E}[Z_{i}].\mathbf{E}[Z_{j}] = \sum_{i=1}^{n} \mathbf{E}[Z_{i}^{2}] + \sum_{i \neq j} (\mathbf{E}[Z_{i}])^{2}  \\
 & =n\mathbf{E}[Z_{i}^{2}] + n(n-1)\mathbf{E}[Z]^{2}
\\ 
 & = n.\mathbf{E}(Z_{i}^{2})
\end{aligned}
$$
</p>
<p>This gives us:</p>
<p>
$$
\mathbf{E} (Z_{i}^{2}) = \mathbf{Var}(Z_{i}) = \frac{1}{n} \sum_{i,j} \mathbf{E}[Z_{i} Z_{j}]
$$
</p>
<p>Now using Chebyshev&rsquo;s inequality on this result we get:</p>
<p>
$$
\mathbf{P}(|\bar{Z}| \geq \epsilon) \leq \frac{\mathbf{Var}(Z_{i})}{\epsilon^{2}} = \frac{1}{n\epsilon^{2}} \sum_{i, j} \mathbf{E}[Z_{i}Z_{j}] 
$$
</p>
<p>We will come back to these results back again.</p>
<h3 id="check-point-3-moment-generating-functions-and-chernoff-bounds">Check Point 3: Moment Generating Functions and Chernoff Bounds</h3>
<p>Given a random variable $Z$, the corresponding M.G.F is:</p>
<p>
$$
M_{Z}(\lambda) = \mathbf{E}[\exp(\lambda Z)]
$$
</p>
<p>The <strong>chernoff bound</strong> is a statistical bound stated as follows, given a random variable we have:</p>
<p>
$$
\mathbf{P}(|Z - \mathbf{E}[Z]| \geq \epsilon) \leq \min_{\lambda\geq {0}} \mathbf{E}[\lambda |Z - \mathbf{E}[Z]|) e^{-\lambda\epsilon} = \min_{{\lambda\geq 0}} M_{Z - \mathbf{E}[Z]}(\lambda) e^{-\lambda t}
$$
</p>
<p>Proof for the same is:</p>
<p>
$$
\begin{aligned}
\mathbf{P} (|Z - \mathbf{E}[Z]| \geq \epsilon)  & = \mathbf{P} (\exp(\lambda|Z-\mathbf{E}[Z]|) \geq e^{\lambda \epsilon}) \\
 & \leq \mathbf{E}(\exp(\lambda|Z- \mathbf{E}[Z]|)).e^{-\lambda\epsilon} = \min_{{\lambda\geq 0}} M_{Z - \mathbf{E}[Z]}(\lambda) e^{-\lambda t}
\end{aligned}
$$
</p>
<p>This is the chernoff bound. The reason we care about this is that it plays well with summations over Independent distributions, which is a consequence of moment generating functions. We get the following results:</p>
<p>
$$
M_{Z_{1} + Z_{2} +\dots +Z_{n}}(\lambda) = \prod_{i=1}^{n} M_{Z_{i}}(\lambda)
$$
</p>
<p>A result of this is</p>

            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
<a href="https://github.com/MandaKausthubh" target="_blank" rel="noopener noreferrer me"
    title="Github">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
</a>
<a href="https://x.com/MandaKausthubh" target="_blank" rel="noopener noreferrer me"
    title="Twitter">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z">
    </path>
</svg>
</a>
<a href="https://www.linkedin.com/in/kausthubh-manda/" target="_blank" rel="noopener noreferrer me"
    title="Linkedin">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
</a>
</div>
    <small class="footer_copyright">
        © 2025 Kausthubh Manda.
        
    </small>
</footer><a href="#" title="" id="totop">
    <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor" stroke="currentColor" viewBox="0 96 960 960">
    <path d="M283 704.739 234.261 656 480 410.261 725.739 656 677 704.739l-197-197-197 197Z"/>
</svg>

</a>


    






    
    <script async src="http://localhost:1313/js/main.js" ></script>

    

</body>
</html>
